{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvWFQRT8FgJn",
        "outputId": "4c8536b9-4168-481e-b106-f488025c0273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 23 16:22:56 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YWN8V7aMCw-X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Define the path to the zip file\n",
        "zip_path = '/content/drive/MyDrive/multi-label-classification-competition-2023.zip'\n",
        "# Check if the file exists\n",
        "if os.path.exists(zip_path):\n",
        "    # Define the directory to unzip to\n",
        "    unzip_dir = '/content/drive/MyDrive/'\n",
        "    # Create a ZipFile Object\n",
        "    with zipfile.ZipFile(zip_path) as zip_ref:\n",
        "        # Extract all the contents of the zip file into the defined directory\n",
        "        zip_ref.extractall(unzip_dir)\n",
        "        print(\"Files have been unzipped successfully.\")\n",
        "else:\n",
        "    print(\"The specified zip file does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xSuK0hcfEnK",
        "outputId": "b53c8b18-cd3d-4642-9328-56f52a06a2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ImageID  Labels                                            Caption\n",
            "0          0.jpg       1   Woman in swim suit holding parasol on sunny day.\n",
            "1          1.jpg    1 19  A couple of men riding horses on top of a gree...\n",
            "2          2.jpg       1  They are brave for riding in the jungle on tho...\n",
            "3          3.jpg  8 3 13  a black and silver clock tower at an intersect...\n",
            "4          4.jpg   8 3 7   A train coming to a stop on the tracks out side.\n",
            "...          ...     ...                                                ...\n",
            "29991  29995.jpg   8 1 2  A picture of a truck that is in the middle of ...\n",
            "29992  29996.jpg       1  A plate topped with a pizza being cut with a s...\n",
            "29993  29997.jpg       1          A man riding a snowboard on top of  snow.\n",
            "29994  29998.jpg       1   This photo shows people skiing in the mountains.\n",
            "29995  29999.jpg       1  Two young men playing soccer and fighting for ...\n",
            "\n",
            "[29996 rows x 3 columns]\n",
            "        ImageID                                            Caption\n",
            "0     30000.jpg  A little girl waring a krispy kreme hat holdin...\n",
            "1     30001.jpg  A beautiful young woman holding an orange fris...\n",
            "2     30002.jpg  A group of people sitting on couch next to a c...\n",
            "3     30003.jpg         A person on a snowboard rides on the hill.\n",
            "4     30004.jpg  A man riding a skateboard with a helmet on in ...\n",
            "...         ...                                                ...\n",
            "9995  39995.jpg  A group of men riding surfboards riding a mass...\n",
            "9996  39996.jpg  A motorcycle parked next to a car in a parking...\n",
            "9997  39997.jpg            a little boy that is playing with a wii\n",
            "9998  39998.jpg  group of kids play Frisbee golf in the middle ...\n",
            "9999  39999.jpg   A man in a gray jacket standing next to a woman.\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "import re\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "datafolderpath =\"/content/drive/MyDrive/COMP5329S1A2Dataset/data\"\n",
        "testcsvpath = \"/content/drive/MyDrive/COMP5329S1A2Dataset/test.csv\"\n",
        "traincsvpath = \"/content/drive/MyDrive/COMP5329S1A2Dataset/train.csv\"\n",
        "# load data to dataframe\n",
        "with open(traincsvpath) as file:\n",
        "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    df_train_origin = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "with open(testcsvpath) as file:\n",
        "    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\n",
        "    df_test = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")\n",
        "df_train_origin = df_train_origin.drop(columns = 'Caption').join(df_train_origin['Caption'].str.replace('\\\"', ''))\n",
        "df_test = df_test.drop(columns = 'Caption').join(df_test['Caption'].str.replace('\\\"', ''))\n",
        "print(df_train_origin )\n",
        "print(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHTEv9bwHCc8",
        "outputId": "4da0fb93-3912-477d-ef4e-3b5e2c500d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 13s 81ms/step\n",
            "32/32 [==============================] - 3s 85ms/step\n",
            "32/32 [==============================] - 3s 84ms/step\n",
            "32/32 [==============================] - 3s 85ms/step\n",
            "32/32 [==============================] - 3s 86ms/step\n",
            "32/32 [==============================] - 3s 86ms/step\n",
            "32/32 [==============================] - 3s 87ms/step\n",
            "32/32 [==============================] - 3s 87ms/step\n",
            "32/32 [==============================] - 3s 88ms/step\n",
            "32/32 [==============================] - 3s 87ms/step\n",
            "32/32 [==============================] - 3s 88ms/step\n",
            "32/32 [==============================] - 3s 89ms/step\n",
            "32/32 [==============================] - 3s 89ms/step\n",
            "32/32 [==============================] - 3s 89ms/step\n",
            "32/32 [==============================] - 3s 89ms/step\n",
            "32/32 [==============================] - 3s 90ms/step\n",
            "32/32 [==============================] - 3s 90ms/step\n",
            "32/32 [==============================] - 3s 91ms/step\n",
            "32/32 [==============================] - 3s 92ms/step\n",
            "32/32 [==============================] - 3s 92ms/step\n",
            "32/32 [==============================] - 3s 92ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 95ms/step\n",
            "32/32 [==============================] - 3s 95ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "10/10 [==============================] - 2s 164ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import backend as K\n",
        "import tensorflow.keras.backend as K\n",
        "# Initialize stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to preprocess captions\n",
        "def preprocess_caption(caption):\n",
        "    # Convert to lowercase\n",
        "    caption = caption.lower()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(caption)\n",
        "    # Remove punctuation\n",
        "    tokens = [token for token in tokens if token not in string.punctuation]\n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
        "    # Stemming\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "\n",
        "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "# Preprocess captions\n",
        "df_train_origin['Caption'] = df_train_origin['Caption'].apply(preprocess_caption)\n",
        "df_test['Caption'] = df_test['Caption'].apply(preprocess_caption)\n",
        "\n",
        "# Convert labels into binary form\n",
        "mlb = MultiLabelBinarizer()\n",
        "binary_labels = mlb.fit_transform(df_train_origin['Labels'].str.split())\n",
        "\n",
        "# Convert captions into numerical features\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "caption_features = vectorizer.fit_transform(df_train_origin['Caption']).toarray()\n",
        "\n",
        "# Load pre-trained ResNet50\n",
        "base_model = ResNet50(weights='imagenet')\n",
        "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
        "\n",
        "\n",
        "# Function to preprocess images and extract features in batches\n",
        "def extract_features_batch(img_paths,model, batch_size=1024):\n",
        "    n = len(img_paths)\n",
        "    features = []\n",
        "    for i in range(0, n, batch_size):\n",
        "        batch_paths = img_paths[i:i+batch_size]\n",
        "        batch_imgs = np.array([img_to_array(load_img(path, target_size=(224, 224))) for path in batch_paths])\n",
        "        \n",
        "        batch_imgs = preprocess_input(batch_imgs)\n",
        "        batch_features = model.predict(batch_imgs)\n",
        "        features.extend(batch_features)\n",
        "    return np.array(features)\n",
        "\n",
        "# Extract features from images\n",
        "image_features = extract_features_batch([os.path.join(datafolderpath, img_path) for img_path in df_train_origin['ImageID']],feature_extractor)\n",
        "\n",
        "# Combine features\n",
        "final_features = np.concatenate([caption_features, image_features], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(final_features.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(binary_labels.shape[1], activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=[f1_score])\n",
        "\n",
        "# Define callbacks\n",
        "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Train the model\n",
        "model.fit(final_features, binary_labels, epochs=20, batch_size=32, validation_split=0.2, callbacks=[checkpoint, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63dNN53oSnwb",
        "outputId": "196b77d1-a251-462d-edf5-a26d68b75ab1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1395 - f1_score: 0.6969 - val_loss: 0.1097 - val_f1_score: 0.7533\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1089 - f1_score: 0.7583 - val_loss: 0.1037 - val_f1_score: 0.7677\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0995 - f1_score: 0.7778 - val_loss: 0.1009 - val_f1_score: 0.7730\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0932 - f1_score: 0.7908 - val_loss: 0.0990 - val_f1_score: 0.7783\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0881 - f1_score: 0.8004 - val_loss: 0.0981 - val_f1_score: 0.7801\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0831 - f1_score: 0.8105 - val_loss: 0.0968 - val_f1_score: 0.7852\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0790 - f1_score: 0.8196 - val_loss: 0.0954 - val_f1_score: 0.7888\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0750 - f1_score: 0.8285 - val_loss: 0.0957 - val_f1_score: 0.7887\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0713 - f1_score: 0.8377 - val_loss: 0.0944 - val_f1_score: 0.7916\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0679 - f1_score: 0.8447 - val_loss: 0.0949 - val_f1_score: 0.7906\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0642 - f1_score: 0.8542 - val_loss: 0.0942 - val_f1_score: 0.7954\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0609 - f1_score: 0.8614 - val_loss: 0.0948 - val_f1_score: 0.7981\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0580 - f1_score: 0.8677 - val_loss: 0.0933 - val_f1_score: 0.7974\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0553 - f1_score: 0.8743 - val_loss: 0.0944 - val_f1_score: 0.7992\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.0525 - f1_score: 0.8822 - val_loss: 0.0942 - val_f1_score: 0.8002\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0495 - f1_score: 0.8882 - val_loss: 0.0954 - val_f1_score: 0.8007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7130432020>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess test captions\n",
        "test_caption_features = vectorizer.transform(df_test['Caption']).toarray()\n",
        "\n",
        "# Extract features from test images\n",
        "test_image_features = extract_features_batch([os.path.join(datafolderpath, img_path) for img_path in df_test['ImageID']],feature_extractor)\n",
        "\n",
        "# Combine test features\n",
        "test_final_features = np.concatenate([test_caption_features, test_image_features], axis=1)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_final_features)\n",
        "# Convert predictions to binary\n",
        "binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Convert binary predictions to labels\n",
        "predicted_labels = mlb.inverse_transform(binary_predictions)\n",
        "\n",
        "# Prepare submission dataframe\n",
        "submission_df = pd.DataFrame({\n",
        "    'ImageID': df_test['ImageID'],\n",
        "    'Labels': [' '.join(map(str, labels)) for labels in predicted_labels]\n",
        "})\n",
        "\n",
        "# Write submission dataframe to CSV\n",
        "submission_df.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRt893FsZXoN",
        "outputId": "72abb3a5-5795-4d76-fc95-a3d84478e779"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 3s 92ms/step\n",
            "32/32 [==============================] - 3s 93ms/step\n",
            "32/32 [==============================] - 3s 93ms/step\n",
            "32/32 [==============================] - 3s 93ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 95ms/step\n",
            "32/32 [==============================] - 3s 93ms/step\n",
            "32/32 [==============================] - 3s 94ms/step\n",
            "32/32 [==============================] - 3s 93ms/step\n",
            "25/25 [==============================] - 3s 132ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}